{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n##  Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n-  Create a <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html?context=analytics\" target=\"_blank\" rel=\"noopener no referrer\">here</a>).\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Install and import dependecies"}, {"metadata": {}, "cell_type": "code", "source": "%pip install langchain | tail -n 1\n%pip install elasticsearch | tail -n 1\n%pip install langchain_elasticsearch | tail -n 1\n%pip install sentence_transformers | tail -n 1\n%pip install humanize | tail -n 1\n%pip install pandas | tail -n 1\n%pip install rouge_score | tail -n 1\n%pip install nltk | tail -n 1\n%pip install wget | tail -n 1\n%pip install ibm_watsonx_ai | tail -n 1\n%pip install \"pydantic==1.10.0\" | tail -n 1\n%pip install \"ibm-watson-machine-learning>=1.0.327\" | tail -n 1", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: certifi in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.2.2)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain_elasticsearch) (2.0.4)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: humanize in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (4.9.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from nltk->rouge_score) (4.65.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from nltk) (4.65.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: wget in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (3.2)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from lomond->ibm-watson-machine-learning>=1.0.349->ibm_watsonx_ai) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from pydantic==1.10.0) (4.11.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from lomond->ibm-watson-machine-learning>=1.0.327) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import os, getpass\nimport pandas as pd\nimport humanize\nimport random\nfrom typing import Optional, Any, Iterable, List", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "credentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": getpass.getpass(\"Please enter your WML api key (hit enter): \")\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the project id\nThe API requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id.\n\n**Hint**: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be `Projects / <project name> /`. Click on the `<project name>` link. Then get the `project_id` from Project's Manage tab (Project -> Manage -> General -> Details).\n"}, {"metadata": {}, "cell_type": "code", "source": "try:\n    project_id = os.environ[\"PROJECT_ID\"]\nexcept KeyError:\n    project_id = input(\"Please enter your project_id (hit enter): \")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"data\"></a>\n## Data (test) loading"}, {"metadata": {}, "cell_type": "markdown", "source": "Download the test dataset. This dataset is used to calculate the metrics score for selected model, defined prompts and parameters."}, {"metadata": {}, "cell_type": "code", "source": "import wget\n\nquestions_test_filename = 'questions_test.csv'\nquestions_train_filename = 'questions_train.csv'\nquestions_test_url = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/RAG/questions_test.csv'\nquestions_train_url = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/RAG/questions_train.csv'\n\n\nif not os.path.isfile(questions_test_filename): \n    wget.download(questions_test_url, out=questions_test_filename)\n\n\nif not os.path.isfile(questions_train_filename): \n    wget.download(questions_train_url, out=questions_train_filename)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "filename_test = './questions_test.csv'\nfilename_train =  './questions_train.csv'\n\ntest_data = pd.read_csv(filename_test)\ntrain_data = pd.read_csv(filename_train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Inspect data sample"}, {"metadata": {}, "cell_type": "code", "source": "train_data.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Build up knowledge base\n\nThe current state-of-the-art in RAG is to create dense vector representations of the knowledge base in order to calculate the semantic similarity to a given user query.\n\nWe can generate dense vector representations using embedding models. In this notebook, we use <a href=\"https://www.sbert.net/\" target=\"_blank\" rel=\"noopener no referrer\">Sentence Transformers</a> <a href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\" target=\"_blank\" rel=\"noopener no referrer\">all-MiniLM-L6-v2</a> to embed both the knowledge base passages and user queries. `all-MiniLM-L6-v2` is a performant open-source model that is small enough to run locally.\n\nA vector database is optimized for dense vector indexing and retrieval. This notebook uses <a href=\"https://python.langchain.com/docs/integrations/vectorstores/elasticsearch#basic-example\" target=\"_blank\" rel=\"noopener no referrer\">Elasticsearch</a>, a distributed, RESTful search and analytics engine, capable of performing both vector and lexical search. It is built on top of the Apache Lucene library, which offers good speed and performance with all-MiniLM-L6-v2 embedding model."}, {"metadata": {}, "cell_type": "markdown", "source": "The dataset we are using is already split into self-contained passages that can be ingested by Elasticsearch. \n\nThe size of each passage is limited by the embedding model's context window (which is 256 tokens for `all-MiniLM-L6-v2`)."}, {"metadata": {}, "cell_type": "markdown", "source": "### Load knowledge base documents\n\nLoad set of documents used further to build knowledge base. "}, {"metadata": {}, "cell_type": "code", "source": "knowledge_base_dir = \"./knowledge_base\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "my_path = f\"{os.getcwd()}/knowledge_base\"\nif not os.path.isdir(my_path):\n   os.makedirs(my_path)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "documents_filename = 'knowledge_base/psgs.tsv'\ndocuments_url = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/RAG/psgs.tsv'\n\n\nif not os.path.isfile(documents_filename): \n    wget.download(documents_url, out=documents_filename)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "documents = pd.read_csv(f\"{knowledge_base_dir}/psgs.tsv\", sep='\\t', header=0)\ndocuments['indextext'] = documents['title'].astype(str) + \"\\n\" + documents['text']\ndocuments = documents[:1000]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Create an embedding function\n\nNote that you can feed a custom embedding function to be used by Elasticsearch. The performance of Elasticsearch may differ depending on the embedding model used."}, {"metadata": {}, "cell_type": "code", "source": "from langchain.embeddings import SentenceTransformerEmbeddings\nfrom langchain.embeddings.base import Embeddings\n\nemb_func = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"models\"></a>\n## Foundation Models on watsonx"}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining model\nYou need to specify `model_id` that will be used for inferencing:"}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n\nmodel_id = ModelTypes.FLAN_UL2", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the model parameters\nWe need to provide a set of model parameters that will influence the result:"}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\nfrom ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n\nparameters = {\n    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n    GenParams.MIN_NEW_TOKENS: 1,\n    GenParams.MAX_NEW_TOKENS: 50\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Initialize the `Model` class."}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models import Model\n\nwatsonx_granite = Model(\n    model_id=model_id.value,\n    credentials=credentials,\n    project_id=project_id,\n    params=parameters\n).to_langchain()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"elastic_conn\"></a>\n\nWe'll use the Cloud ID to identify our deployment, because we are using Elastic Cloud deployment. To find the Cloud ID for your deployment, go to https://cloud.elastic.co/deployments and select your deployment.\nTo find the password for the `elastic` user, go to https://cloud.elastic.co/deployments and select your deployment. Then on the left-hand sided menu select the `Security` settings.\nClick on the `Reset password` button and copy the generated password.\n\n\nThe following cell retrieves the Elasticsearch Cloud ID and password for the `elastic` user from the environment if available and prompts you otherwise."}, {"metadata": {}, "cell_type": "code", "source": "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\ntry:\n    es_cloud_id = os.environ[\"ELASTIC_CLOUD_ID\"]\nexcept KeyError:\n    es_cloud_id = input(\"Please enter your Elasticsearch Cloud ID (hit enter): \")\n\n\ntry:\n    es_password = os.environ[\"ELASTIC_PASSWORD\"]\nexcept KeyError:\n    es_password = input(\"Please enter your Elasticsearch PASSWORD (hit enter): \")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"elasticsearchstore\"></a>\n## Set up ElasticsearchStore connector from Langchain\n\n\nWe first create a regular Elasticsearch Python client connection. Then we pass it into LangChain's ElasticsearchStore wrapper together with the WatsonX model based embedding function.\n\nConsult the LangChain documentation For more information about <a href=\"https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html\" target=\"_blank\" rel=\"noopener no referrer\">ElasticsearchStore</a> connector."}, {"metadata": {}, "cell_type": "code", "source": "from langchain_elasticsearch import ElasticsearchStore\nfrom elasticsearch import Elasticsearch\n\n# Create the client instance\nes_connection = Elasticsearch(\n    cloud_id=es_cloud_id,\n    basic_auth=(\"elastic\", es_password)\n)\n\n# Successful response!\nes_connection.info()\n\n\nknowledge_base = ElasticsearchStore(es_connection=es_connection,\n                                    index_name=\"test_index\",\n                                    embedding=emb_func,\n                                    strategy=ElasticsearchStore.ApproxRetrievalStrategy(),\n                                    distance_strategy=\"DOT_PRODUCT\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"elasticsearchstore_index\"></a>\n### Embed and index documents with Elasticsearch\n\n**Note: Could take several minutes if you don't have pre-built indices**"}, {"metadata": {}, "cell_type": "code", "source": "if es_connection.indices.exists(index=\"test_index\"):\n    es_connection.indices.delete(index=\"test_index\")\n_ = knowledge_base.add_texts(texts=documents.indextext.tolist(),\n                             metadatas=[{'title': title, 'id': doc_id}\n                                for (title, doc_id) in\n                                zip(documents.title, documents.id)],  # filter on these!\n                             index_name=\"test_index\",\n                             ids=[str(i) for i in documents.id]  # unique for each doc\n                            )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Let's take a look in Elasticsearch what the LangChain wrapper has created. First we display the newly created index (\"tables\" in Elasticsearch are always called \"index\"). Note the field `vector` of type `dense_vector` with `dot_product` similarity."}, {"metadata": {}, "cell_type": "code", "source": "dict(es_connection.indices.get(index=\"test_index\"))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Verify the number of documents loaded into the Elasticsearch index."}, {"metadata": {}, "cell_type": "code", "source": "doc_count = es_connection.count(index='test_index')[\"count\"]\ndoc_count", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Let's retrieve a random document as a sample. Note the embedding in the vector field, that was generated with the WatsonX embedding model."}, {"metadata": {}, "cell_type": "code", "source": "dict(es_connection.get(index=\"test_index\", id=random.randint(0, len(documents)-1)))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Display the total size and indexing time of the new index in Elasticsearch."}, {"metadata": {}, "cell_type": "code", "source": "index_stats = es_connection.indices.stats(index=\"test_index\").get('_all').get('primaries')\nprint(\"Index size:    \" + humanize.naturalsize(index_stats.get('store').get('size_in_bytes')))\nprint(\"Indexing time: \" + humanize.precisedelta(index_stats.get('indexing').get('index_time_in_millis')/1000, minimum_unit='minutes'))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"predict\"></a>\n## Generate a retrieval-augmented response to a question"}, {"metadata": {}, "cell_type": "markdown", "source": "`RetrievalQA` is a chain to do question answering.\n\n**Hint:** To use Chain interface from LangChain with watsonx.ai models you must call `model.to_langchain()` method. \n\nIt returns `WatsonxLLM` wrapper compatible with LangChain CustomLLM specification."}, {"metadata": {}, "cell_type": "markdown", "source": "### Select questions\n\nThe prompts we will use to test the RAG flow"}, {"metadata": {}, "cell_type": "code", "source": "questions_and_answers = {\n            'names of founding fathers of the united states?': \"Thomas Jefferson::James Madison::John Jay::George Washington::John Adams::Benjamin Franklin::Alexander Hamilton\",\n            'who played in the super bowl in 2013?': 'Baltimore Ravens::San Francisco 49ers',\n            'when did bucharest become the capital of romania?': '1862'\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Retrieve relevant context\n\nFetch paragraphs similar to the question"}, {"metadata": {}, "cell_type": "code", "source": "from langchain.chains import RetrievalQA\n\nqa = RetrievalQA.from_chain_type(llm=watsonx_granite, chain_type=\"stuff\",verbose=True, retriever=knowledge_base.as_retriever(), return_source_documents=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "results = []\n\n\nfor question in questions_and_answers.keys():\n\n    result = qa.invoke({'query': question})\n\n    print(\"result: \", result)\n    results.append( result)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Get the set of chunks for one of the questions."}, {"metadata": {}, "cell_type": "code", "source": "for idx, result in enumerate(results):\n    print(\"=========\")\n    print(\"Question = \", result['query'])\n    print(\"Answer = \", result['result'])\n    print(\"Expected Answer(s) (may not be appear with exact wording in the dataset) = \", questions_and_answers[result['query']])\n    print(\"\\n\")\n    print(\"Source documents:\")\n    print(*(x.page_content for x in result['source_documents']), sep='\\n')\n    print(\"\\n\")\n    ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "---"}, {"metadata": {}, "cell_type": "markdown", "source": "Copyright \u00a9 2023 IBM. This notebook and its source code are released under the terms of the MIT License."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}